{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "\n",
        "class stratifiedKFold:\n",
        "  def __init__(self, n_split, shuffle, random_state):\n",
        "    self.n_split = n_split\n",
        "    self.shuffle = shuffle\n",
        "    self.random_state = random_state\n",
        "\n",
        "  def split(self, X, y):\n",
        "    if (self.shuffle and self.random_state) is not None:\n",
        "      np.random.seed(self.random_state)\n",
        "\n",
        "    idx = np.arange(len(y))\n",
        "    if self.shuffle:\n",
        "      np.random.shuffle(idx)\n",
        "\n",
        "    y_idx = defaultdict(list)\n",
        "    for i, label in zip(idx, y):\n",
        "      y_idx[label].append(i)\n",
        "\n",
        "    splits = [[] for _ in range(self.n_split)]\n",
        "\n",
        "    for label, i in y_idx.items():\n",
        "      np.random.shuffle(i)\n",
        "      split_portions = [len(i) // self.n_split] * self.n_split\n",
        "      for j in range(len(i) % self.n_split):\n",
        "        split_portions[j] += 1\n",
        "\n",
        "      first = 0\n",
        "      for k in range(self.n_split):\n",
        "        last = first + split_portions[k]\n",
        "        splits[k].extend(i[first:last])\n",
        "        first = last\n",
        "\n",
        "    for i in range(self.n_splits):\n",
        "      test_idx = splits[i]\n",
        "      train_idx = np.concatenate([splits[j] for j in range(self.n_split) if j != i])\n",
        "      yield train_idx, test_idx\n",
        "\n",
        "    def get_n_splits(self):\n",
        "        return self.n_split"
      ],
      "metadata": {
        "id": "bucE2jVgBT_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFnJh-oGLpWI"
      },
      "outputs": [],
      "source": [
        "# to be filled/expand, such as batch size\n",
        "hypers = [\n",
        "    {'lr': []},\n",
        "    {'epochs': []}\n",
        "]\n",
        "\n",
        "# calling the function, results is a list of tuple (best_params, test_acc) where\n",
        "# best_params is the optimal param and test_acc is its corresponding accuracy\n",
        "\n",
        "# results = cross_validate(model, metadata, metadata['dx_encoded'], hypers)\n",
        "\n",
        "def cross_validate(model, X, y, hyperparameters):\n",
        "    outer_fold = stratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "    outer_results = []\n",
        "\n",
        "    # outer fold\n",
        "    for train_idx, test_idx in outer_fold.split(X, y):\n",
        "        X_train, X_test = X[train_idx], X[test_idx]\n",
        "        y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "        inner_fold = stratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "        best_acc = -np.inf\n",
        "        best_params = None\n",
        "\n",
        "        # set up hyperparameter combinations\n",
        "        param_keys = [list(d.keys())[0] for d in hyperparameters]\n",
        "        param_values = [list(d.values())[0] for d in hyperparameters]\n",
        "        combinations = product(*param_values)\n",
        "        hyper_combo = [{param_keys[i]: combo[i] for i in range(len(param_keys))} for combo in combinations]\n",
        "\n",
        "        for param in hyper_combo:\n",
        "            # TODO: replace/remove based on your own implementation\n",
        "            # LEARNING_RATE = param['lr']\n",
        "            # EPOCHS = param['epochs']\n",
        "            # optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "            # total_steps = len(train_loader) * EPOCHS\n",
        "            # scheduler = get_linear_schedule_with_warmup(\n",
        "            #     optimizer,\n",
        "            #     num_warmup_steps=int(0.1 * total_steps),\n",
        "            #     num_training_steps=total_steps\n",
        "            # )\n",
        "\n",
        "            # inner_acc = []\n",
        "\n",
        "            # inner fold\n",
        "            for inner_train_idx, inner_val_idx in inner_fold.split(X_train, y_train):\n",
        "                X_inner_train, X_inner_val = X_train[inner_train_idx], X_train[inner_val_idx]\n",
        "\n",
        "                # TODO: replace/remove based on your own implementation\n",
        "            #     # Create Datasets for inner folds\n",
        "            #     train_dataset = SkinCancerDataset(X_inner_train, IMAGE_DIRS, feature_extractor, transform=train_transform)\n",
        "            #     val_dataset = SkinCancerDataset(X_inner_val, IMAGE_DIRS, feature_extractor, transform=val_test_transform)\n",
        "\n",
        "            #     # Create DataLoaders for inner folds\n",
        "            #     BATCH_SIZE = 128\n",
        "            #     train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
        "            #     val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "            #     # epoch loop (can be coded as a function to reduce redundancy)\n",
        "            #     for epoch in range(EPOCHS):\n",
        "            #       print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
        "            #       print(\"-\" * 10)\n",
        "\n",
        "            #       train_loss, train_acc = train_epoch(model, train_loader, optimizer, scheduler, DEVICE)\n",
        "            #       val_loss, val_acc = eval_epoch(model, val_loader, DEVICE)\n",
        "\n",
        "            #       print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc*100:.2f}%\")\n",
        "            #       print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc*100:.2f}%\")\n",
        "\n",
        "            #     inner_acc.append(val_acc)\n",
        "\n",
        "            # mean_inner_acc = np.mean(inner_acc)\n",
        "\n",
        "            # # Update best score and parameters\n",
        "            # if mean_inner_acc > best_acc:\n",
        "            #     best_acc = mean_inner_acc\n",
        "            #     best_params = param\n",
        "\n",
        "        # Retrain the model with the best parameters on the entire outer training set\n",
        "        # LEARNING_RATE = best_params['lr']\n",
        "        # EPOCHS = best_params['epochs']\n",
        "        # optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "        # total_steps = len(train_loader) * EPOCHS\n",
        "        # scheduler = get_linear_schedule_with_warmup(\n",
        "        #     optimizer,\n",
        "        #     num_warmup_steps=int(0.1 * total_steps),\n",
        "        #     num_training_steps=total_steps\n",
        "        # )\n",
        "\n",
        "        # # Create Datasets for outer folds\n",
        "        # train_dataset = SkinCancerDataset(X_train, IMAGE_DIRS, feature_extractor, transform=train_transform)\n",
        "        # test_dataset = SkinCancerDataset(X_test, IMAGE_DIRS, feature_extractor, transform=val_test_transform)\n",
        "\n",
        "        # # Create DataLoaders for outer folds\n",
        "        # BATCH_SIZE = 128\n",
        "        # train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=True)\n",
        "        # test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n",
        "        # best_test_acc = 0.0\n",
        "\n",
        "        # for epoch in range(EPOCHS):\n",
        "        #   print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
        "        #   print(\"-\" * 10)\n",
        "\n",
        "        #   train_loss, train_acc = train_epoch(model, train_loader, optimizer, scheduler, DEVICE)\n",
        "        #   test_loss, test_acc = eval_epoch(model, test_loader, DEVICE)\n",
        "\n",
        "        #   print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc*100:.2f}%\")\n",
        "        #   print(f\"Val Loss: {test_loss:.4f} | Val Acc: {test_acc*100:.2f}%\")\n",
        "\n",
        "        #   # Checkpoint\n",
        "        #   if test_acc > best_test_acc:\n",
        "        #       best_test_acc = test_acc\n",
        "        #       torch.save(model.state_dict(), 'models/vit_skin_cancer_model.pth')\n",
        "        #       print(\"Model checkpoint saved.\")\n",
        "\n",
        "        outer_results.append((best_params, best_test_acc))\n",
        "\n",
        "    return outer_results"
      ]
    }
  ]
}